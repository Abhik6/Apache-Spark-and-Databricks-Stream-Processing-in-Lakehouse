Welcome back.

In this lecture we will learn about streaming triggers.

So let's start.

In the earlier lectures, we learned about the streaming query, and we also learned how spark structured

streaming works.

We learned that a streaming query is responsible for triggering Microbatches, right?

It will trigger first Micro-batch, and once first Micro-batch is complete, it will trigger the next

Micro-batch.

A spark structured streaming offers us three types of triggers.

We haven't learned about the different trigger types, but we have three triggering options.

So let's try to understand what are those.

So Spark Structured Streaming offers us unspecified fixed interval and available now three types of

triggers.

If we don't specify any kind of trigger it is assumed to be unspecified trigger which is the default

one.

What happens if we don't specify a trigger or in case of unspecified trigger, a streaming query will

trigger one micro batch to process your data once that data is processed.

The first micro batch is complete.

It will immediately trigger the next micro batch, and when the next one finishes, it will immediately

trigger the next micro batch.

And that's what unspecified trigger means.

So in case of unspecified trigger, microbatches will be generated as soon as previous Micro-batch has

completed processing.

How do you specify this trigger?

You don't have to do anything.

Here is an example.

We usually specify triggers at the time of write.

So you start with the data frame dot write stream.

You specify all the options like format checkpoint.

And finally you specify your action to table.

Is the action here.

When do we use this unspecified trigger?

When you need to process your data ASAP as soon as possible.

Maybe in seconds or in milliseconds.

You don't need to specify any trigger, so the streaming query will keep on generating microbatches

as soon as possible, right?

The second type of trigger is known as fixed interval trigger or processing time trigger.

Right.

So in this type of trigger you specify some processing type.

Could be one second, could be two seconds, could be 10s, 15 seconds, minutes or even hours.

So how does it work?

What will happen if you specify a processing time trigger?

Let's try to understand it with an example.

Let's assume I created a streaming write operation with the 30s trigger.

Write processing time equal to 32nd.

What will happen?

The streaming query will start the first micro batch.

The first Micro-batch will go read data from the streaming source, do the processing, and first Micro-batch

will complete.

Let's assume first Micro-batch took 20s to complete.

Your processing time is 30s, but the first Micro-batch finished in 20s, so streaming query will wait

another 10s to make sure the gap between two consecutive Microbatches is 30s.

So it will wait for ten more seconds and add 32nd.

It will start the next micro-batch.

At.

This keeps on going.

Let's assume if a micro-batch took more than 30s, your processing time you have is specified as 32nd,

but the previous micro-batch took 35 seconds.

It is more than 30s, right?

So in that case, the streaming query knows that we already passed the minimum desired gap, right?

So it will immediately start the next micro-batch.

That's what fixed interval or processing time trigger means.

Processing time trigger allows you to make sure there is a fixed interval between two consecutive microbatches.

So what is fixed?

Interval Microbatches will be kicked off at a user specified interval.

When do we use it?

What is the use of this kind of trigger?

We use this type of trigger for collect and process.

What does it mean?

Let's assume you want to collect data for a specified time.

You don't want to take action as soon as possible.

Immediately.

As soon as data is arrived, we start processing it.

You don't want that.

You want to collect a sizable amount of data, let's say for five minutes, ten minutes, 15 minutes.

Right?

And then start processing.

Then you want your micro-batch to start.

So you have a sizable amount of data, and then you want to start processing.

In those scenarios you will implement fix interval.

So you will be collecting data for a fixed interval.

And then your micro-batch will start process it.

And then again you will wait for a fixed interval for data collection.

And then.

Your next micro batch will start to process it.

So that's what the purpose of fixed interval.

The third type of streaming trigger is known as available now trigger or once trigger.

So what happens in this case available now is a one time micro batch trigger to process all available

data and then stop its own.

What does it mean?

Let's try to understand it with an example.

So let's assume you want to implement a scenario where you want to collect data for one hour and then

do the processing right.

How will you do it.

You have fixed interval triggers.

You can implement it using fixed interval.

So interval will be one hour.

Right.

So your streaming query will start processing finish and then wait until one hour.

So you will be collecting data at your streaming source or your at your landing zone.

And after one hour streaming query will trigger the next micro-batch.

Right.

All looks good.

There is no harm in that approach, but you are running continuously your streaming query for one hour

and it's doing nothing.

It's just waiting, waiting or sleeping for one hour so that once the time pass, it can trigger the

next micro-batch.

And if your query is running, it's waiting.

You are consuming compute resources and that's expensive.

Compute resources are expensive.

If your micro-batch data processing takes maybe two minutes.

So you are using two minutes of compute time effectively, but then after two minutes you still need

to wait for one hour.

So 58 minutes you are waiting.

Waiting for data collection.

During that time, whatever compute resource you are using is actually wasted.

You can save that.

So for those kind of scenarios we have available now or once one time trigger.

So in one time trigger what will happen.

You specify that trigger using trigger available now equal to true.

And that's all.

So what will happen.

Your streaming query will start.

It will trigger one micro batch trigger one micro batch to read all the available data at the streaming

source or at your landing zone, right, read all data, process all of it.

And once that processing is done, shut down.

Streaming query will also stop.

In usual case, streaming query keeps on running right, but streaming query will also stop in case

of available now trigger.

But then you again want to start it after one hour.

How do you do that?

You can schedule your application.

Schedule your application to start at every one hour.

So think about that original scenario that we wanted to implement.

We wanted to process data at a one hour interval.

We want to collect data for one hour.

And then whatever data is collected process it may be processing takes 2 minutes to 5 minutes.

Right.

So we can write an streaming job using read stream and write stream is specify the trigger as available

now equal to true.

One time trigger.

And schedule that job to run at one hour interval again and again.

Right.

You can use any scheduler or workflow tool to schedule your job.

So what will happen?

Your job will start.

Read whatever data is available at the landing zone or at your streaming source.

Do all the processing, whatever time it takes two minutes, five minutes, ten minutes, 15 minutes,

whatever.

And once all that data is processed, it will stop, shut down, and your resources are free.

You can release your cluster.

You can leave your resources free.

Save some cost.

And then after an hour again, your scheduler will trigger your job right?

And it will again start processing whatever new data has arrived at your streaming source or at your

landing zone and take it from there.

Process that again shut down.

That's how you can save cost.

So available now is a little tricky.

It works like a batch processing right?

In batch processing what happens?

You start your job, finish all the processing and then stop.

That's all you are done.

Same way is available now.

Trigger all allows you to run your streaming application as a batch processing job.

Whatever data is there, read all that data.

Process all data.

And once that all data is processed, we stop.

Right.

But since you are using streaming APIs, it allows you to do an incremental processing without any extra

coding.

Right?

So available now.

Triggers are interesting ones.

They allow you to implement incremental batch right using the Spark streaming APIs.

But still your code runs like a batch processing code.

So you can implement incremental batch.

And these are used for the same kind of scenario where your execution cycle is maybe in hours or maybe

in days or weeks, whatever.

You don't want to keep on running your resources.

So in those cases you implement the available now trigger.

That's all for this lecture.

In the next lecture we will try to implement one example using available.

Now trigger and run it as a incremental batch.

So it makes a little more sense to you.

See you again.
