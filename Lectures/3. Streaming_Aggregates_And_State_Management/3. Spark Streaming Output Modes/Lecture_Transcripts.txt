Welcome back.

So far we have learned a lot about Spark Structured Streaming.

You learned that Spark Structured Streaming starts a background query thread to trigger Microbatches,

right.

And each micro-batch allows you to implement an incremental data read incremental data processing and

incremental data.

Right.

We learned about spark dot read stream.

We learned about DataFrame dot write stream.

I also talked about different output modes.

We have three output modes append, update and complete.

Right.

So we also talked about calculating aggregates.

And how do you calculate incremental aggregates.

Right.

We talked about for each batch and we learned how to implement merge statement in your for each batch.

So all that is good.

But one more important thing that I want to talk in this lecture is looking at your streaming query

background thread.

Right.

We know that spark structured streaming for each query for each read write pair right.

A spark will start one background query thread which runs in the background and which triggers the microbatches

one after another.

Right?

So how do we look at that query in spark UI?

And how can we get some stats about that query that what that spark streaming query is doing.

Right.

So let me show you some details about the Spark Structured Streaming query behind the scene, and we

will find some details about what kind of details it manages.

And we'll see some stats.

So let's start.

So let me go back to my workspace and reopen the last notebook.

This one is streaming incremental aggregates test suit.

So we are implementing incremental aggregates.

In this example I already have a cluster attached here.

So let me run it right.

And once it is started I'll take you to the spark UI and show you how to look at your spark structured

streaming queries and how to look at important stats.

So starting Silver Stream.

So hopefully a streaming query background thread is already started.

So go to your cluster go to spark UI.

I hope you are already familiar with the spark.

This is the go to place for investigative purposes and to see and understand what is happening behind

the scenes.

So there are various tabs.

I hope you have already learned all that in your spark course will come to a structured streaming tab.

So this last tab shows you all background threads, all the running streaming queries.

So you can see I have a branch ingestion which is in running state gold update which is in running state.

So you come back to the code.

Let me quickly show you the code.

We created two queries in this example, right?

The first one is right stream and we gave a name bronze ingestion.

Right.

The second one is this right stream.

We gave a name to Gold Update and that's what we can see.

Gold update is also running.

Bronze ingestion is also running.

When it is finished you will see something like this.

It is finished.

But since our query is still running you can see the details here.

Refresh this page.

So as of now bronze ingestion has finished one micro batch.

It starts with zero right so zero and then one.

It means we have already executed to micro batches right.

You can come back to your script here and you can see first iteration already passed.

And second iteration data ingestion is done.

We are waiting for 60s.

So to micro batches must have started.

So latest batch is one.

It means zero and one to micro.

Batch is already started.

It shows some details about average process per second.

Average input per second duration since it started first time.

This is the duration.

What was the start time and all that status you can see.

Click the run ID and you will see some more stats.

So let me go to Gold Update, Query and Bronze both in separate tabs and we will see what do we see

there.

Right.

So this is my streaming query bronze ingestion query.

And you can see some states input rate.

It shows you this nice chart for each iteration.

What happened.

So for the first micro batch.

This is your input rate.

And for second micro-batch this one is this is what is your input batch.

So how many records per second we are reading using this query processing rate.

So how many records per second we are processing here.

How many records per second we are processed for the second micro batch at this drops not because query

started becoming slow, it's because there are less number of records in the second iteration.

Or for the second input file, right input rows.

It also shows some data here batch duration.

So it shows some data here right operation duration.

It shows you some stats so you can get some sense out of it right now come back to gold query.

This one is not doing any aggregation.

But our gold query is doing aggregation right.

And since it is doing aggregation so there is an estate store involved behind the scene.

So we will get some more details about the state storage stats.

So you can see same input rates process rates, input rows batch duration and.

At the bottom you will see 3 or 4 stats about the statistics.

So aggregated number of total state is store rows right.

So it tells you how many records this query is maintaining in the state store.

So for the first iteration we had 100 records right.

Maybe for the zeroth iteration we had 65 records.

So 65 unique customers were processed.

And we calculated totals or aggregates for 65 unique customers.

So all those unique customers were stored in the state store, not the entire data, only the aggregates.

So customer ID and both the aggregates that we are calculating total amount and total rewards.

So that 65 was stored for the first Micro-batch we saw 100 unique records.

So 65 unique customers were there for the first Micro-batch some more new customers we identified in

the second Micro-batch.

So total are 100 unique customers in the state store.

Aggregated number of updated state rows.

Right.

So first Micro-batch 65 all were new, so we can expect all 65 were updated in the state store or created

in the state store.

First time second Micro-batch 98 customers were repeating customers, right?

So they purchased something from us.

So we had 100.

Unique customers in the state is stopped after the second iteration, but 98 of them.

Totals for 98 of them were updated, so Estate Store was updated for 98 unique customers so that you

can see from here.

This one is important.

Aggregated estate memory used in bytes.

So for first iteration estate is store.

Was using this much memory right.

So what it is it is in bytes of 128 MB.

Best believe.

So.

Estate store is kind of a data set right.

Whatever we are saving in the state is store or streaming query is saving in the state is store is an

intermediate aggregate data which is required?

Very much required.

We cannot skip that or we cannot ignore that which is very much required to calculate the final totals.

Right.

So and it takes some storage space, it takes some memory when it is loaded into the memory during the

processing.

Right.

So this is an important area to watch out or tune when you are working with the state store.

Or you are calculating a streaming aggregates and behind the scene, spark Structured Streaming is storing

data into the state store.

So this stats is quite important.

You can see some indication 128 MB memory was used for state store at the first operation for zeroth

iteration, and 170 MB memory was used for the first iteration.

So if this keeps on growing you have a problem, right?

So we want to manage this.

We want to manage the amount of memory is used for the state store.

And that's where things become a little complex in the stream processing.

Right.

So we want to understand how do we minimize the size of the state store, and how do we handle the memory

requirement for the state store.

These two things are very important aspects.

If you are calculating aggregates or using streaming joints, we will learn it later.

All those operations are stateful operations.

They require a state store.

So we'll talk about it.

How to look at the state store requirement and how to limit the number of records in the state store,

and how to limit the memory, how to manage the memory in the state store.

So that's all.

But we wanted to understand how do we see the stats of our streaming query.

We learn that.

Let me go back to this.

Refresh this page again.

By now my queries must have been finished.

So both are finished.

But it doesn't mean that if it is finished you cannot see the stats.

You can still go to your gold update query run ID and you will see complete stats, right?

So you can see three iterations.

Now because we executed three iterations and memory used in the first iteration is 128 MB.

Memory used in the second iteration was 178 MB and third iteration is 180 MB.

So data keeps on growing in the state store, so the memory requirement also keeps on growing.

You want to limit the memory requirement for state store.

You have to limit the amount of data stored in the state store.

How to handle that is the topic for the next lecture.

See you again!

Keep learning and keep growing.
