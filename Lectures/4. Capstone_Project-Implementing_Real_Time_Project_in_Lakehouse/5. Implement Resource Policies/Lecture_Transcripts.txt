Welcome Back.

We designed the lakehouse platform with data storage and security in place.

Let me show you the current state of our design.

Here it is.

So in this architecture,

your team can create a Databricks all-purpose cluster or a Job cluster to run their Spark applications.

However, we cannot leave it open for users to create unlimited clusters with unlimited capacity.

How do we control it?

We can manage cluster resources and costs using workspace management and cluster policies.

Let me add a new layer to our architecture diagram.

So we have Databricks workspace management and cluster policies at the top of the stack.

Your developers and other users are assigned different roles in the workspace

and given access to appropriate policies.

And we can define cluster policies to do the following.

Limit the cluster type and size of a cluster

Limit the number of clusters per user

Control the cost per cluster

Control the cluster configurations, such as node type and autoscaling capacity.

Preconfigure packages, dependencies, and cluster log location

Great!

So we finished the lakehouse platform design.

This diagram represents a typical architecture of a lakehouse platform for most of the projects.

And we can develop our dev, test, and production environments using the same architecture.

That's all for this lecture.

See you again in the following lecture.

Keep Learning and Keep Growing.
